{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MapReduce\n",
    "\n",
    "Tomado y adaptado del curso de Big Data por Raúl Ramos Pollán [GitHub](https://github.com/rramosp/20172.bigdata)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesamiento de información con MAP-REDUCE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Un ejemplo\n",
    "Tenemos un log de la siguiente manera\n",
    "\n",
    "    2012-01-01 09:08 BOG Libros 88.56 Discover\n",
    "    2012-01-01 09:52 BGA Libros 62.41 Discover\n",
    "    2012-01-01 10:08 MED Musica 93.37 Visa\n",
    "    2012-01-01 10:58 MED Musica 395.93 Discover\n",
    "    2012-01-01 14:38 BOG Musica 113.24 MasterCard\n",
    "    2012-01-01 14:44 BGA Libros 290.5 Visa\n",
    "    2012-01-01 16:26 MED Musica 246.12 Efectivo\n",
    "\n",
    "Con el `dia`, `hora`, `ciudad`, `producto`, `importe` y `medio de pago` de compras realizadas en almacenes de una cierta cadena. Queremos obtener el total del importe de compras realizadas en cada ciudad. Una forma de hacerlo es la siguiente:\n",
    "\n",
    "1) procesamos cada linea y, de cada una, generamos un par `(ciudad, importe)`, obteniendo los siguientes pares:\n",
    "\n",
    "    (BOG, 88.56)\n",
    "    (BGA, 62.41)\n",
    "    (MED, 93.37)\n",
    "    (MED, 395.93)\n",
    "    (BOG, 113.24)\n",
    "    (BGA, 290.5)\n",
    "    (MED, 246.12)\n",
    "    \n",
    "2) agrupamos las tuplas generadas por el valor del primer componente:\n",
    "\n",
    "    (BOG, [88.56, 113.24])\n",
    "    (BGA, [62.41, 290.5])\n",
    "    (MED, [93.37, 395.93, 246.12])\n",
    "     \n",
    "3) sumamos los elementos de cada lista para cada ciudad:\n",
    "\n",
    "    (BOG, 201.8)\n",
    "    (BGA, 352.91)\n",
    "    (MED, 735.42)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tres fases\n",
    "\n",
    "El primer paso en el ejemplo anterior se denomina **MAP** y, para cada registro de entrada, genera una tupla de formato `(clave, valor)`.\n",
    "\n",
    "El segundo paso se denomina **SHUFFLE** y lo que hace es recopilar todas las tuplas generadas en el MAP anterior de cada `clave` y construir una lista con todos los valores generados. Es decir, una tupla de formato `(clave, lista_de_valores)` para cada clave.\n",
    "\n",
    "El tercer paso se denomina **REDUCE** y, para cada clave, agrega los resultados de la lista generada en el SHUFFLE anterior.\n",
    "\n",
    "Esta forma de procesar los datos constituye un **modelo de programación** llamado *MAP-REDUCE* y que está implementado por varios frameworks de programación y en varios lenguajes, de forma que el programador **solo implementa las funciones MAP y REDUCE** y el framework se encarga del shuffle."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mr-job\n",
    "\n",
    "\n",
    "Usaremos el framework [mr-job](https://pythonhosted.org/mrjob) para hacer nuestros programas map-reduce. El siguiente código implementa el proceso que acabamos de describir. Fíjate cómo sólo programamos las funciones `mapper` y `reducer`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si están trabajando en Google Colab pueden usar `!pip install mrjob` para instalar la librería."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile py-files/mr-basico.py\n",
    "from mrjob.job import MRJob\n",
    "import os\n",
    "\n",
    "class Compras(MRJob):\n",
    "\n",
    "    def mapper(self, _, line):\n",
    "        tokens = line.split()\n",
    "        yield tokens[2], float(tokens[4])\n",
    "\n",
    "    def reducer(self, key, values):\n",
    "        yield key, sum(values)\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    c = Compras()\n",
    "    c.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script python py-files/mr-basico.py -r inline --quiet\n",
    "2012-01-01 09:08 BOG Libros 88.56 Discover\n",
    "2012-01-01 09:52 BGA Libros 62.41 Discover\n",
    "2012-01-01 10:08 MED Musica 93.37 Visa\n",
    "2012-01-01 10:58 MED Musica 395.93 Discover\n",
    "2012-01-01 14:38 BOG Musica 113.24 MasterCard\n",
    "2012-01-01 14:44 BGA Libros 290.5 Visa\n",
    "2012-01-01 16:26 MED Musica 246.12 Efectivo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Prueba a eliminar el término `--quiet` de la celda anterior y así verás los mensajes que emite **mr-job** durante la ejecución del programa. Útil para diagnosticar errores en la ejecución del código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script python py-files/mr-basico.py -r inline\n",
    "2012-01-01 09:08 BOG Libros 88.56 Discover\n",
    "2012-01-01 09:52 BGA Libros 62.41 Discover\n",
    "2012-01-01 10:08 MED Musica 93.37 Visa\n",
    "2012-01-01 10:58 MED Musica 395.93 Discover\n",
    "2012-01-01 14:38 BOG Musica 113.24 MasterCard\n",
    "2012-01-01 14:44 BGA Libros 290.5 Visa\n",
    "2012-01-01 16:26 MED Musica 246.12 Efectivo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Otro ejemplo\n",
    "\n",
    "En este ejemplo partimos de una tuplas (personaA, personaB) que representa que la personaA considera a la personaB como amiga. La relación no es simétrica. El siguiente programa cuenta cuantas amigos considera cada persona que tiene.\n",
    "\n",
    "Fíjate que la entrada es en formato JSON y cómo usamos la librería `json` de Python para convertir la entrada JSON en una lista de valores.\n",
    "\n",
    "```\n",
    "[\"juan\", \"pepe\"]\n",
    "[\"juan\", \"sebastian\"]\n",
    "[\"raul\", \"pepe\"]\n",
    "[\"ana\", \"pepe\"]\n",
    "[\"juan\", \"ana\"]\n",
    "[\"ana\", \"pedro\"]\n",
    "```\n",
    "\n",
    "1) procesamos cada linea y, de cada una, generamos un par `(ciudad, importe)`, obteniendo los siguientes pares:\n",
    "\n",
    "    (juan, 1)\n",
    "    (juan, 1)\n",
    "    (raul, 1)\n",
    "    (ana, 1)\n",
    "    (juan, 1)\n",
    "    (ana, 1)\n",
    "    \n",
    "2) agrupamos las tuplas generadas por el valor del primer componente:\n",
    "\n",
    "    (juan, [1, 1, 1])\n",
    "    (raul, [1])\n",
    "    (ana, [1, 1])\n",
    "     \n",
    "3) sumamos los elementos de cada lista para cada ciudad:\n",
    "\n",
    "    (juan, 3)\n",
    "    (raul, 1)\n",
    "    (ana, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile py-files/mr-amigos.py\n",
    "from mrjob.job import MRJob\n",
    "import json\n",
    "\n",
    "class Amigos(MRJob):\n",
    "\n",
    "    def mapper(self, _, line):\n",
    "        record = json.loads(line)\n",
    "        yield record[0], 1\n",
    "\n",
    "    def reducer(self, key, values):\n",
    "        yield key, sum(values)\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    c = Amigos()\n",
    "    c.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script python py-files/mr-amigos.py -r inline --quiet\n",
    "[\"juan\", \"pepe\"]\n",
    "[\"juan\", \"sebastian\"]\n",
    "[\"raul\", \"pepe\"]\n",
    "[\"ana\", \"pepe\"]\n",
    "[\"juan\", \"ana\"]\n",
    "[\"ana\", \"pedro\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instrumentación y runners\n",
    "\n",
    "Usamos la instrumentación para encontrar errores, entender nuestro código, etc. Por ahora usamos `stderr.write` para saber cuantas veces se llama a cada función. Fíjate como el `reducer` se llama una vez por cada clave distinta que generamos en el `mapper`. Cuando usemos varios procesos o máquinas tendremos que recurrir a otros tipos de instrumentación.\n",
    "\n",
    "Fíjate también que `values` en la función `reducer` es un **generador** [[ref](http://www.jeffknupp.com/blog/2013/04/07/improve-your-python-yield-and-generators-explained/)], es decir, no contiene en sí una lista de valores, sino que cada vez que va devolviendo valores uno a uno hasta que se acaban. Típicamente esto sucede porque va obteniendo los valores que devuelve de un _stream_ de entrada como un fichero, o una conexión remota. Por esto sólo podemos iterar sobre todos los valores **una única vez**.\n",
    "\n",
    "Como ahora en el `reducer` queremos obtenter ambos el número de valores que tenemos y la suma de los mismos, tenemos que modificar nuestro código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile py-files/mr-basico-instrumentado.py\n",
    "from mrjob.job import MRJob\n",
    "from sys import stdin, stderr\n",
    "import os\n",
    "\n",
    "class Compras(MRJob):\n",
    "\n",
    "    def mapper(self, _, line):\n",
    "        tokens = line.split()\n",
    "        stderr.write(\"MAPPER >> {0}\\n\".format(line))\n",
    "        #print(\"mapper >>\", line)\n",
    "        yield tokens[2], float(tokens[4])\n",
    "        \n",
    "    def reducer(self, key, values):\n",
    "        n_values, sum_values = 0, 0\n",
    "        for i in values:\n",
    "            n_values += 1\n",
    "            sum_values += i\n",
    "        stderr.write(\"REDUCER >> {0}, number of values {1}\\n\".format(key, n_values))\n",
    "        #print(\"reducer >>\", key, \"number of values\", n_values)\n",
    "        yield key, sum_values\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    c = Compras()\n",
    "    c.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%script python py-files/mr-basico-instrumentado.py --quiet\n",
    "2012-01-01 09:08 BOG Libros 88.56 Discover\n",
    "2012-01-01 09:52 BGA Libros 62.41 Discover\n",
    "2012-01-01 10:08 MED Musica 93.37 Visa\n",
    "2012-01-01 10:58 MED Musica 395.93 Discover\n",
    "2012-01-01 14:38 BOG Musica 113.24 MasterCard\n",
    "2012-01-01 14:44 BGA Libros 290.5 Visa\n",
    "2012-01-01 16:26 MED Musica 246.12 Efectivo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local runner\n",
    "\n",
    "Los programas en **mr-job** pueden ejecutarse en distintos **runners**. Fíjate en la opción `-r` cuando ejecutamos nuestro código. Los runners posibles son los siguientes:\n",
    "\n",
    "- **inline**: todos los `mapper` y `reducer` corren en el mismo proceso. Esta opción es útil para empezar a desarrollar un código y verificarlo funcionalmente.\n",
    "\n",
    "- **local**: cada `mapper` y `reducer` corren en distintos procesos independientes en la misma máquina. Con esta opción podemos hacer una primera simulación de nuetro código en un entorno distribuido.\n",
    "\n",
    "- **hadoop**: nuestro código se ejecuta en un cluster Hadoop\n",
    "\n",
    "Instrumentar código con un local runner o en Hadoop ya no es tan fácil porque cada ejecución de las funciones `mapper` y `reducer` se hace en procesos o en máquinas distintas. Si no tenemos un mecanismo para recoger y coordinar la instrumentación generada en los distintos procesos o máquinas perderemos al menos parte de ella.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%script python py-files/mr-basico-instrumentado.py -r local --quiet\n",
    "2012-01-01 09:08 BOG Libros 88.56 Discover\n",
    "2012-01-01 09:52 BGA Libros 62.41 Discover\n",
    "2012-01-01 10:08 MED Musica 93.37 Visa\n",
    "2012-01-01 10:58 MED Musica 395.93 Discover\n",
    "2012-01-01 14:38 BOG Musica 113.24 MasterCard\n",
    "2012-01-01 14:44 BGA Libros 290.5 Visa\n",
    "2012-01-01 16:26 MED Musica 246.12 Efectivo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distintos frameworks usan distintos mecanismos para instrumentar el código distribuido. En este caso (mrjob/Hadoop) usamos los `counters`, y el framework asegura un estado global de los mismos de manera consistente. Ahora necesitamos mostrar los mensajes de salida del framework para ver el valor final de los contadores.\n",
    "\n",
    "Usamos a partir de ahora el fichero `Data/compras.txt` que tiene 30 registros con el mismo formato que el usado hasta ahora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ../Data/compras.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile py-files/mr-basico-instrumentado-counters.py\n",
    "from mrjob.job import MRJob\n",
    "from sys import stdin\n",
    "import os\n",
    "\n",
    "class Compras(MRJob):\n",
    "\n",
    "    def mapper(self, _, line):\n",
    "        tokens = line.split()\n",
    "        self.increment_counter(\"llamadas al map\", \"numero\", 1)\n",
    "        yield tokens[2], float(tokens[4])\n",
    "        \n",
    "    def reducer(self, key, values):\n",
    "        n_values, sum_values = 0,0\n",
    "        for i in values:\n",
    "            n_values += 1\n",
    "            sum_values += i\n",
    "        self.increment_counter(\"longitud valores reduce\", key, n_values )\n",
    "        yield key, sum_values\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    c = Compras()\n",
    "    c.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%script python py-files/mr-basico-instrumentado-counters.py -r local ../Data/compras.txt\n",
    "--"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Controlando el número de mappers y reducers\n",
    "Ahora cambiamos la instrumentación para que cuente el número de llamadas de cada función por cada proceso. Puedes controlar el número de mappers y reducers al ejecutar tu programa como se indica abajo. Prueba a ejecutar el código con distintos números de mappers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile py-files/mr-basico-instrumentado-counters-tasks.py\n",
    "from mrjob.job import MRJob\n",
    "from sys import stdin\n",
    "import os\n",
    "\n",
    "class Compras(MRJob):\n",
    "\n",
    "    def mapper(self, _, line):\n",
    "        tokens = line.split()\n",
    "        self.increment_counter(\"map: proceso \"+str(os.getpid()), \"numero\", 1)\n",
    "        yield tokens[2], float(tokens[4])\n",
    "        \n",
    "    def reducer(self, key, values):\n",
    "        n_values, sum_values = 0,0\n",
    "        for i in values:\n",
    "            n_values += 1\n",
    "            sum_values += i\n",
    "        self.increment_counter(\"longitud valores reduce: proceso \"+str(os.getpid()), key, n_values )\n",
    "        yield key, sum_values\n",
    "        \n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    c = Compras()\n",
    "    c.run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_la linea entera que se ejecuta a continuación es la siguiente_\n",
    "\n",
    "    python files/mr-basico-instrumentado-counters-tasks.py \n",
    "           -r local \n",
    "           --jobconf mapred.map.tasks=5 \n",
    "           --jobconf mapred.reduce.tasks=1 \n",
    "           ../Data/compras.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%script python py-files/mr-basico-instrumentado-counters-tasks.py -r local --jobconf mapred.map.tasks=5 --jobconf mapred.reduce.tasks=1 ../Data/compras.txt\n",
    "--"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combiners\n",
    "\n",
    "los combiners permiten resumir los datos que emite cada proceso map antes de que lleguen al reduce y así reducir el tráfico de red que sale de los procesos map y que entra en los reducers. Los combiners se ejecutan en la misma máquina que el map, alimentándose directamente de la salida de éste. Típicamente un combiner tiene la misma implementación que el `reducer` si es que éste **es asociativo**. Si no, puede tener otra implementación particular. Fíjate en la relación entre el número de procesos map y el número de valores que le entran a cada reduce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile py-files/mr-basico-combiners.py\n",
    "from mrjob.job import MRJob\n",
    "from sys import stdin\n",
    "import os\n",
    "\n",
    "class Compras(MRJob):\n",
    "\n",
    "    def mapper(self, _, line):\n",
    "        tokens = line.split()\n",
    "        self.increment_counter(\"map: \", \"numero\", 1)\n",
    "        yield tokens[2], float(tokens[4])\n",
    "        \n",
    "    def combiner(self, key, values):\n",
    "        yield key, sum(values)\n",
    "        \n",
    "    def reducer(self, key, values):\n",
    "        n_values, sum_values = 0,0\n",
    "        for i in values:\n",
    "            n_values += 1\n",
    "            sum_values += i\n",
    "        self.increment_counter(\"longitud valores reduce: \", key, n_values )\n",
    "        yield key, sum_values\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    c = Compras()\n",
    "    c.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script python py-files/mr-basico-combiners.py -r local ../Data/compras.txt\n",
    "--"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo WordCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile py-files/mr-basico-wordcount.py\n",
    "from mrjob.job import MRJob\n",
    "import re\n",
    "WORD_RE = re.compile(r\"[\\w']+\")\n",
    "\n",
    "class MRWordFreqCount(MRJob):\n",
    "\n",
    "    def mapper(self, _, line):\n",
    "        for word in WORD_RE.findall(line):\n",
    "            yield word.lower(), 1\n",
    "\n",
    "    def combiner(self, word, counts):\n",
    "        yield word, sum(counts)\n",
    "\n",
    "    def reducer(self, word, counts):\n",
    "        yield word, sum(counts)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MRWordFreqCount.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script python py-files/mr-basico-wordcount.py -r inline -q\n",
    "Ancient influences have helped spawn variant interpretations \n",
    "of the nature of history which have evolved over the centuries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile py-files/mr-wordcount-max.py\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import re\n",
    "\n",
    "WORD_RE = re.compile(r\"[\\w']+\")\n",
    "\n",
    "\n",
    "class MRMostUsedWord(MRJob):\n",
    "\n",
    "    def mapper_get_words(self, _, line):\n",
    "        # yield each word in the line\n",
    "        for word in WORD_RE.findall(line):\n",
    "            yield (word.lower(), 1)\n",
    "\n",
    "    def combiner_count_words(self, word, counts):\n",
    "        # sum the words we've seen so far\n",
    "        yield (word, sum(counts))\n",
    "\n",
    "    def reducer_count_words(self, word, counts):\n",
    "        # send all (num_occurrences, word) pairs to the same reducer.\n",
    "        # num_occurrences is so we can easily use Python's max() function.\n",
    "        yield None, (sum(counts), word)\n",
    "\n",
    "    # discard the key; it is just None\n",
    "    def reducer_find_max_word(self, _, word_count_pairs):\n",
    "        # each item of word_count_pairs is (count, word),\n",
    "        # so yielding one results in key=counts, value=word\n",
    "        yield max(word_count_pairs)\n",
    "\n",
    "    def steps(self):\n",
    "        return [\n",
    "            MRStep(mapper=self.mapper_get_words,\n",
    "                   combiner=self.combiner_count_words,\n",
    "                   reducer=self.reducer_count_words),\n",
    "            MRStep(reducer=self.reducer_find_max_word)\n",
    "        ]\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MRMostUsedWord.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script python py-files/mr-wordcount-max.py -r inline -q ../Data/text.txt\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile py-files/mr-wordcount-max-clean.py\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import re\n",
    "\n",
    "WORD_RE = re.compile(r\"[\\w']+\")\n",
    "\n",
    "\n",
    "class MRMostUsedWord(MRJob):\n",
    "\n",
    "    stopwords = ['ourselves', 'hers', 'between', 'yourself', 'but', 'again', 'there', 'about', 'once', 'during', 'out',\n",
    "    'very', 'having', 'with', 'they', 'own', 'an', 'be', 'some', 'for', 'do', 'its', 'yours', 'such', 'into', 'of', 'most',\n",
    "    'itself', 'other', 'off', 'is', 's', 'am', 'or', 'who', 'as', 'from', 'him', 'each', 'the', 'themselves', 'until', 'below',\n",
    "    'are', 'we', 'these', 'your', 'his', 'through', 'don', 'nor', 'me', 'were', 'her', 'more', 'himself', 'this', 'down', 'should',\n",
    "    'our', 'their', 'while', 'above', 'both', 'up', 'to', 'ours', 'had', 'she', 'all', 'no', 'when', 'at', 'any', 'before', 'them',\n",
    "    'same', 'and', 'been', 'have', 'in', 'will', 'on', 'does', 'yourselves', 'then', 'that', 'because', 'what', 'over', 'why', 'so',\n",
    "    'can', 'did', 'not', 'now', 'under', 'he', 'you', 'herself', 'has', 'just', 'where', 'too', 'only', 'myself', 'which', 'those',\n",
    "    'i', 'after', 'few', 'whom', 't', 'being', 'if', 'theirs', 'my', 'against', 'a', 'by', 'doing', 'it', 'how', 'further', 'was', 'here', 'than']\n",
    "\n",
    "    def mapper_get_words(self, _, line):\n",
    "        # yield each word in the line\n",
    "        for word in WORD_RE.findall(line):\n",
    "            if word.lower() not in self.stopwords:\n",
    "                yield (word.lower(), 1)\n",
    "\n",
    "    def combiner_count_words(self, word, counts):\n",
    "        # sum the words we've seen so far\n",
    "        yield (word, sum(counts))\n",
    "\n",
    "    def reducer_count_words(self, word, counts):\n",
    "        # send all (num_occurrences, word) pairs to the same reducer.\n",
    "        # num_occurrences is so we can easily use Python's max() function.\n",
    "        yield None, (sum(counts), word)\n",
    "\n",
    "    # discard the key; it is just None\n",
    "    def reducer_find_max_word(self, _, word_count_pairs):\n",
    "        # each item of word_count_pairs is (count, word),\n",
    "        # so yielding one results in key=counts, value=word\n",
    "        yield max(word_count_pairs)\n",
    "\n",
    "    def steps(self):\n",
    "        return [\n",
    "            MRStep(mapper=self.mapper_get_words,\n",
    "                   combiner=self.combiner_count_words,\n",
    "                   reducer=self.reducer_count_words),\n",
    "            MRStep(reducer=self.reducer_find_max_word)\n",
    "        ]\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MRMostUsedWord.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script python py-files/mr-wordcount-max-clean.py -r inline -q ../Data/text.txt\n",
    "--"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hadoop\n",
    "\n",
    "Para ejecutar la siguiente celda asegúrese de que los servicios de Hadoop están arriba y haya un archivo en la ruta `/user/<username>/grep/input`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplace <username> y <filename> según corresponda\n",
    "%%script python py-files/mr-wordcount-max-clean.py -r hadoop --output-dir hdfs:///user/<username>/grep/output hdfs:///user/<username>/grep/input/<filename>\n",
    "--"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bigdata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": true,
   "toc_threshold": 6,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "cb1c08858b1ba5829aaa3ef347d742b945887b262c4429f3e07f40f45731aece"
   }
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
